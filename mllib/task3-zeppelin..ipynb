{
  "metadata": {
    "name": "task3-zeppelin",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, month, year, avg, to_date\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler\nfrom pyspark.ml.regression import LinearRegression, RandomForestRegressor\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.regression import GBTRegressor\nfrom pyspark.ml import Pipeline\n\nspark \u003d SparkSession.builder.appName(\"Evapotranspiration_MLlib\").getOrCreate()\n\ndf \u003d spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/opt/data/weatherData.csv\")\n\nprint(\"Data loaded successfully!\")\nprint(f\"Total records: {df.count()}\")\n# df.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_clean \u003d df.withColumnRenamed(\"precipitation_hours (h)\", \"precipitation_hours\").withColumnRenamed(\"sunshine_duration (s)\", \"sunshine_duration\") \\\n            .withColumnRenamed(\"wind_speed_10m_max (km/h)\", \"wind_speed\").withColumnRenamed(\"et0_fao_evapotranspiration (mm)\", \"evapotranspiration\")\n\ndf_clean \u003d df_clean.withColumn(\"date_parsed\", to_date(col(\"date\"), \"M/d/yyyy\")).withColumn(\"year\", year(\"date_parsed\")).withColumn(\"month\", month(\"date_parsed\"))\n\n# Filter for May (month \u003d 5)\ndf_may \u003d df_clean.filter(col(\"month\") \u003d\u003d 5)\n\ndf_features \u003d df_may.select(\"precipitation_hours\", \"sunshine_duration\", \"wind_speed\", \"evapotranspiration\").na.drop()\n\nprint(f\"May records: {df_features.count()}\")\ndf_features.describe().show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfeature_cols \u003d [\"precipitation_hours\", \"sunshine_duration\", \"wind_speed\"]\n\nassembler \u003d VectorAssembler(inputCols\u003dfeature_cols, outputCol\u003d\"features_raw\")\nscaler \u003d StandardScaler(inputCol\u003d\"features_raw\", outputCol\u003d\"features\", withStd\u003dTrue, withMean\u003dTrue)\n\ndf_assembled \u003d assembler.transform(df_features)\nscaler_model \u003d scaler.fit(df_assembled)\ndf_scaled \u003d scaler_model.transform(df_assembled)\n\nprint(\"Features assembled and scaled!\")\ndf_scaled.select(\"features\", \"evapotranspiration\").show(5, truncate\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Split data: 80% training, 20% validation\ntrain_data, test_data \u003d df_scaled.randomSplit([0.8, 0.2], seed\u003d42)\n\nprint(f\"Training samples: {train_data.count()}\")\nprint(f\"Validation samples: {test_data.count()}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Linear Regression\nlr \u003d LinearRegression(\n    featuresCol\u003d\"features\",\n    labelCol\u003d\"evapotranspiration\",\n    maxIter\u003d100,\n    regParam\u003d0.3,\n    elasticNetParam\u003d0.8)\n\nlr_model \u003d lr.fit(train_data)\n\n# Random Forest Regresssor\nrf \u003d RandomForestRegressor(\n    featuresCol\u003d\"features\",\n    labelCol\u003d\"evapotranspiration\",\n    numTrees\u003d100,\n    maxDepth\u003d10,\n    seed\u003d42)\n\nrf_model \u003d rf.fit(train_data)\n\nprint(\"\u003d\u003d\u003d Random Forest Model \u003d\u003d\u003d\")\nprint(f\"Features: {feature_cols}\")\nprint(f\"Feature Importances: {rf_model.featureImportances}\")\n\n# Gradient Boosted Trees Regressor\ngbt \u003d GBTRegressor(\n    featuresCol\u003d\"features\",\n    labelCol\u003d\"evapotranspiration\",\n    maxIter\u003d100,\n    seed\u003d42)\n\ngbt_model \u003d gbt.fit(train_data)\nprint(\"\\n\u003d\u003d\u003d Gradient Boosted Trees (GBT) Model \u003d\u003d\u003d\")\nprint(f\"Features: {feature_cols}\")\nprint(f\"Feature Importances: {gbt_model.featureImportances}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Model evaluation\nevaluator_rmse \u003d RegressionEvaluator(labelCol\u003d\"evapotranspiration\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nevaluator_r2 \u003d RegressionEvaluator(labelCol\u003d\"evapotranspiration\", predictionCol\u003d\"prediction\", metricName\u003d\"r2\")\nevaluator_mae \u003d RegressionEvaluator(labelCol\u003d\"evapotranspiration\", predictionCol\u003d\"prediction\", metricName\u003d\"mae\")\n\n# Linear Regression predictions\nlr_predictions \u003d lr_model.transform(test_data)\nlr_rmse \u003d evaluator_rmse.evaluate(lr_predictions)\nlr_r2 \u003d evaluator_r2.evaluate(lr_predictions)\nlr_mae \u003d evaluator_mae.evaluate(lr_predictions)\n\n# Random Forest predictions\nrf_predictions \u003d rf_model.transform(test_data)\nrf_rmse \u003d evaluator_rmse.evaluate(rf_predictions)\nrf_r2 \u003d evaluator_r2.evaluate(rf_predictions)\nrf_mae \u003d evaluator_mae.evaluate(rf_predictions)\n\n# GBT predictions\ngbt_predictions \u003d gbt_model.transform(test_data)\ngbt_rmse \u003d evaluator_rmse.evaluate(gbt_predictions)\ngbt_r2 \u003d evaluator_r2.evaluate(gbt_predictions)\ngbt_mae \u003d evaluator_mae.evaluate(gbt_predictions)\n\nprint(\"\u003d\u003d\u003d Linear Regression Evaluation \u003d\u003d\u003d\")\nprint(f\"RMSE: {lr_rmse:.4f}\")\nprint(f\"R-2: {lr_r2:.4f}\")\nprint(f\"MAE: {lr_mae:.4f}\")\n\nprint(\"\\n\u003d\u003d\u003d Random Forest Evaluation \u003d\u003d\u003d\")\nprint(f\"RMSE: {rf_rmse:.4f}\")\nprint(f\"R-2: {rf_r2:.4f}\")\nprint(f\"MAE: {rf_mae:.4f}\")\n\nprint(\"\\n\u003d\u003d\u003d Gradient Boosted Trees Evaluation \u003d\u003d\u003d\")\nprint(f\"RMSE: {gbt_rmse:.4f}\")\nprint(f\"R-2: {gbt_r2:.4f}\")\nprint(f\"MAE: {gbt_mae:.4f}\")\n\n# \u003d\u003d\u003d Linear Regression Evaluation \u003d\u003d\u003d\n# RMSE: 0.6757\n# R-2: 0.6792\n# MAE: 0.5153\n\n# \u003d\u003d\u003d Random Forest Evaluation \u003d\u003d\u003d\n# RMSE: 0.4948\n# R-2: 0.8279\n# MAE: 0.3855\n\n# \u003d\u003d\u003d Gradient Boosted Trees Evaluation \u003d\u003d\u003d\n# RMSE: 0.4972\n# R-2: 0.8263\n# MAE: 0.3871"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Find patterns where evapotranspiration \u003c 1.5mm\nlow_et \u003d df_features.filter(col(\"evapotranspiration\") \u003c 1.5)\n\nprint(\"\u003d\u003d\u003d Conditions for Evapotranspiration \u003c 1.5mm \u003d\u003d\u003d\")\nprint(f\"Number of days with ET \u003c 1.5mm: {low_et.count()}\")\n\nlow_et_stats \u003d low_et.agg(\n    avg(\"precipitation_hours\").alias(\"mean_precipitation_hours\"),\n    avg(\"sunshine_duration\").alias(\"mean_sunshine_duration\"),\n    avg(\"wind_speed\").alias(\"mean_wind_speed\"))\n\nprint(\"\\nMean values when evapotranspiration \u003c 1.5mm:\")\nlow_et_stats.show()\n\n# \u003d\u003d\u003d Conditions for Evapotranspiration \u003c 1.5mm \u003d\u003d\u003d\n# Number of days with ET \u003c 1.5mm: 134\n\n# Mean values when evapotranspiration \u003c 1.5mm:\n# +------------------------+----------------------+------------------+\n# |mean_precipitation_hours|mean_sunshine_duration|   mean_wind_speed|\n# +------------------------+----------------------+------------------+\n# |      22.134328358208954|    1593.0579850746274|18.490298507462686|\n# +------------------------+----------------------+------------------+"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Check prediction floors\nprint(\"\u003d\u003d\u003d Model Prediction Ranges on Test Data \u003d\u003d\u003d\")\n\nlr_preds \u003d lr_model.transform(test_data)\nprint(f\"Linear Regression: Min\u003d{lr_preds.agg({\u0027prediction\u0027: \u0027min\u0027}).collect()[0][0]:.4f}, Max\u003d{lr_preds.agg({\u0027prediction\u0027: \u0027max\u0027}).collect()[0][0]:.4f}\")\n\nrf_preds \u003d rf_model.transform(test_data)\nprint(f\"Random Forest:     Min\u003d{rf_preds.agg({\u0027prediction\u0027: \u0027min\u0027}).collect()[0][0]:.4f}, Max\u003d{rf_preds.agg({\u0027prediction\u0027: \u0027max\u0027}).collect()[0][0]:.4f}\")\n\ngbt_preds \u003d gbt_model.transform(test_data)\nprint(f\"GBT:               Min\u003d{gbt_preds.agg({\u0027prediction\u0027: \u0027min\u0027}).collect()[0][0]:.4f}, Max\u003d{gbt_preds.agg({\u0027prediction\u0027: \u0027max\u0027}).collect()[0][0]:.4f}\")\n\n# \u003d\u003d\u003d Model Prediction Ranges on Test Data \u003d\u003d\u003d\n# Linear Regression: Min\u003d1.7946, Max\u003d5.3591\n# Random Forest:     Min\u003d1.6081, Max\u003d6.3490\n# GBT:               Min\u003d1.2874, Max\u003d6.9398\n\n# Here, in Linear Regression and Random Forest, for unseen data, the predictions\u0027 range varies above 1.5mm.\n# So those can not be used to predict the mean precipitation_hours, sunshine, and wind_speed during May in 2026 to have evapotranspiration lower than 1.5mm\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport random\nfrom pyspark.sql.types import StructType, StructField, DoubleType\nfrom pyspark.sql.functions import avg, col\n\n# Grid Search Parameters\n# Based on May analysis: High Rain, Low Sun, Variable Wind\nNUM_SAMPLES \u003d 50000\nMIN_SUNSHINE \u003d 0.0         # 0 hours\nMAX_SUNSHINE \u003d 3600.0      # 1 hour \nMIN_WIND \u003d 15.0            # Range around the 18.5 km/h mean\nMAX_WIND \u003d 25.0            # Range around the 18.5 km/h mean\nMIN_PRECIP \u003d 20.0          # Range around 22h\nMAX_PRECIP \u003d 24.0          # Range around 22h\n\nsynthetic_data \u003d []\nfor _ in range(NUM_SAMPLES):\n    synthetic_data.append((\n        random.uniform(MIN_PRECIP, MAX_PRECIP),\n        random.uniform(MIN_SUNSHINE, MAX_SUNSHINE),\n        random.uniform(MIN_WIND, MAX_WIND)\n    ))\n\nschema \u003d StructType([\n    StructField(\"precipitation_hours\", DoubleType(), True),\n    StructField(\"sunshine_duration\", DoubleType(), True),\n    StructField(\"wind_speed\", DoubleType(), True)\n])\n\ndf_synthetic \u003d spark.createDataFrame(synthetic_data, schema)\n\nprint(f\"Generating {NUM_SAMPLES} synthetic realistic weather points...\")\n\n# Transform features\ndf_synthetic_assembled \u003d assembler.transform(df_synthetic)\ndf_synthetic_scaled \u003d scaler_model.transform(df_synthetic_assembled)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Predict using GBT\npredictions \u003d gbt_model.transform(df_synthetic_scaled)\n\n# Keep ONLY the days where Predicted ET \u003c 1.5\nsuccessful_days \u003d predictions.filter(col(\"prediction\") \u003c 1.5)\nsuccess_count \u003d successful_days.count()\n\nprint(f\"Found {success_count} days with ET \u003c 1.5mm out of {NUM_SAMPLES} samples.\")\n\nif success_count \u003e 0:\n    # Calculate Mean of those successful days\n    mean_values \u003d successful_days.agg(\n        avg(\"precipitation_hours\").alias(\"avg_precip\"),\n        avg(\"sunshine_duration\").alias(\"avg_sun\"),\n        avg(\"wind_speed\").alias(\"avg_wind\"),\n        avg(\"prediction\").alias(\"avg_et\")\n    ).collect()[0]\n    \n    recommended_stats \u003d {\n        \u0027precip\u0027: mean_values[\"avg_precip\"],\n        \u0027sun\u0027: mean_values[\"avg_sun\"],\n        \u0027wind\u0027: mean_values[\"avg_wind\"]\n    }\n    \n    print(f\"\\n*** Recommended Mean Values for May 2026 (Target \u003c 1.5mm) ***\")\n    print(f\"Precipitation Hours: {recommended_stats[\u0027precip\u0027]:.2f} hours\")\n    print(f\"Sunshine Duration: {recommended_stats[\u0027sun\u0027]:.2f} seconds ({recommended_stats[\u0027sun\u0027]/3600:.2f} hours)\")\n    print(f\"Wind Speed: {recommended_stats[\u0027wind\u0027]:.2f} km/h\")\n    print(f\"\\nExpected Average ET with these conditions: {mean_values[\u0027avg_et\u0027]:.4f} mm\")\n\nelse:\n    print(f\"\\nFAILURE: Could not find any weather combinations with ET \u003c 1.5mm.\")\n    print(\"Model indicates \u003c 1.5mm is extremely difficult/impossible within these search parameters.\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Predict using Linear Regression model on the SAME synthetic data\nlr_predictions \u003d lr_model.transform(df_synthetic_scaled)\n\n# Filter for Target and Calculate Means\nlr_successful \u003d lr_predictions.filter(col(\"prediction\") \u003c 1.5)\nlr_success_count \u003d lr_successful.count()\n\nprint(f\"Found {lr_success_count} days with ET \u003c 1.5mm out of {NUM_SAMPLES} samples.\")\n\nif lr_success_count \u003e 0:\n    lr_mean \u003d lr_successful.agg(\n        avg(\"precipitation_hours\").alias(\"avg_precip\"),\n        avg(\"sunshine_duration\").alias(\"avg_sun\"),\n        avg(\"wind_speed\").alias(\"avg_wind\"),\n        avg(\"prediction\").alias(\"avg_et\")\n    ).collect()[0]\n    \n    print(f\"\\n*** Linear Regression - Recommended Mean Values for May 2026 ***\")\n    print(f\"Precipitation Hours: {lr_mean[\u0027avg_precip\u0027]:.2f} hours\")\n    print(f\"Sunshine Duration: {lr_mean[\u0027avg_sun\u0027]:.2f} seconds ({lr_mean[\u0027avg_sun\u0027]/3600:.2f} hours)\")\n    print(f\"Wind Speed: {lr_mean[\u0027avg_wind\u0027]:.2f} km/h\")\n    print(f\"Expected Average ET: {lr_mean[\u0027avg_et\u0027]:.4f} mm\")\nelse:\n    print(\"Linear Regression could not find any scenarios with ET \u003c 1.5mm.\")\n    lr_mean \u003d None\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Predict using Random Forest model on the SAME synthetic data\nrf_predictions \u003d rf_model.transform(df_synthetic_scaled)\n\n# Filter for Target and Calculate Means\nrf_successful \u003d rf_predictions.filter(col(\"prediction\") \u003c 1.5)\nrf_success_count \u003d rf_successful.count()\n\nprint(f\"Found {rf_success_count} days with ET \u003c 1.5mm out of {NUM_SAMPLES} samples.\")\n\nif rf_success_count \u003e 0:\n    rf_mean \u003d rf_successful.agg(\n        avg(\"precipitation_hours\").alias(\"avg_precip\"),\n        avg(\"sunshine_duration\").alias(\"avg_sun\"),\n        avg(\"wind_speed\").alias(\"avg_wind\"),\n        avg(\"prediction\").alias(\"avg_et\")\n    ).collect()[0]\n    \n    print(f\"\\n*** Random Forest - Recommended Mean Values for May 2026 ***\")\n    print(f\"Precipitation Hours: {rf_mean[\u0027avg_precip\u0027]:.2f} hours\")\n    print(f\"Sunshine Duration: {rf_mean[\u0027avg_sun\u0027]:.2f} seconds ({rf_mean[\u0027avg_sun\u0027]/3600:.2f} hours)\")\n    print(f\"Wind Speed: {rf_mean[\u0027avg_wind\u0027]:.2f} km/h\")\n    print(f\"Expected Average ET: {rf_mean[\u0027avg_et\u0027]:.4f} mm\")\nelse:\n    print(\"Random Forest could not find any scenarios with ET \u003c 1.5mm.\")\n    rf_mean \u003d None\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n"
    }
  ]
}