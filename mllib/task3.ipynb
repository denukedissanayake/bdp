{
  "metadata": {
    "name": "dbp-task3-2",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, month, year, avg, to_date\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler\nfrom pyspark.ml.regression import LinearRegression, RandomForestRegressor\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.regression import GBTRegressor\nfrom pyspark.ml import Pipeline\n\nspark \u003d SparkSession.builder.appName(\"Evapotranspiration_MLlib\").getOrCreate()\n\ndf \u003d spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/opt/data/weatherData.csv\")\n\nprint(\"Data loaded successfully!\")\nprint(f\"Total records: {df.count()}\")\n# df.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_clean \u003d df.withColumnRenamed(\"precipitation_hours (h)\", \"precipitation_hours\").withColumnRenamed(\"sunshine_duration (s)\", \"sunshine_duration\") \\\n            .withColumnRenamed(\"wind_speed_10m_max (km/h)\", \"wind_speed\").withColumnRenamed(\"et0_fao_evapotranspiration (mm)\", \"evapotranspiration\")\n\ndf_clean \u003d df_clean.withColumn(\"date_parsed\", to_date(col(\"date\"), \"M/d/yyyy\")).withColumn(\"year\", year(\"date_parsed\")).withColumn(\"month\", month(\"date_parsed\"))\n\n# Filter for May (month \u003d 5)\ndf_may \u003d df_clean.filter(col(\"month\") \u003d\u003d 5)\n\ndf_features \u003d df_may.select(\"precipitation_hours\", \"sunshine_duration\", \"wind_speed\", \"evapotranspiration\").na.drop()\n\nprint(f\"May records: {df_features.count()}\")\ndf_features.describe().show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfeature_cols \u003d [\"precipitation_hours\", \"sunshine_duration\", \"wind_speed\"]\n\nassembler \u003d VectorAssembler(inputCols\u003dfeature_cols, outputCol\u003d\"features_raw\")\nscaler \u003d StandardScaler(inputCol\u003d\"features_raw\", outputCol\u003d\"features\", withStd\u003dTrue, withMean\u003dTrue)\n\ndf_assembled \u003d assembler.transform(df_features)\nscaler_model \u003d scaler.fit(df_assembled)\ndf_scaled \u003d scaler_model.transform(df_assembled)\n\nprint(\"Features assembled and scaled!\")\ndf_scaled.select(\"features\", \"evapotranspiration\").show(5, truncate\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Split data: 80% training, 20% validation\ntrain_data, test_data \u003d df_scaled.randomSplit([0.8, 0.2], seed\u003d42)\n\nprint(f\"Training samples: {train_data.count()}\")\nprint(f\"Validation samples: {test_data.count()}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Initialize Linear Regression\nlr \u003d LinearRegression(\n    featuresCol\u003d\"features\",\n    labelCol\u003d\"evapotranspiration\",\n    maxIter\u003d100,\n    regParam\u003d0.3,\n    elasticNetParam\u003d0.8)\n\nlr_model \u003d lr.fit(train_data)\n\nprint(\"\u003d\u003d\u003d Linear Regression Model \u003d\u003d\u003d\")\nprint(f\"Coefficients: {lr_model.coefficients}\")\nprint(f\"Intercept: {lr_model.intercept}\")\nprint(f\"R-squared (training): {lr_model.summary.r2}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Random Forest for comparison\nrf \u003d RandomForestRegressor(\n    featuresCol\u003d\"features\",\n    labelCol\u003d\"evapotranspiration\",\n    numTrees\u003d100,\n    maxDepth\u003d10,\n    seed\u003d42)\n\nrf_model \u003d rf.fit(train_data)\n\nprint(\"\u003d\u003d\u003d Random Forest Model \u003d\u003d\u003d\")\nprint(f\"Feature Importances: {rf_model.featureImportances}\")\nprint(f\"Features: {feature_cols}\")\n\nfrom pyspark.ml.regression import GBTRegressor # Remove this\n\n# Gradient Boosted Trees (Adding for better non-linear performance)\ngbt \u003d GBTRegressor(\n    featuresCol\u003d\"features\",\n    labelCol\u003d\"evapotranspiration\",\n    maxIter\u003d100,\n    seed\u003d42)\n\ngbt_model \u003d gbt.fit(train_data)\nprint(\"\\n\u003d\u003d\u003d Gradient Boosted Trees (GBT) Model \u003d\u003d\u003d\")\nprint(f\"Feature Importances: {gbt_model.featureImportances}\")\nprint(f\"Features: {feature_cols}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Model evaluation\nevaluator_rmse \u003d RegressionEvaluator(labelCol\u003d\"evapotranspiration\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nevaluator_r2 \u003d RegressionEvaluator(labelCol\u003d\"evapotranspiration\", predictionCol\u003d\"prediction\", metricName\u003d\"r2\")\nevaluator_mae \u003d RegressionEvaluator(labelCol\u003d\"evapotranspiration\", predictionCol\u003d\"prediction\", metricName\u003d\"mae\")\n\n# Linear Regression predictions\nlr_predictions \u003d lr_model.transform(test_data)\nlr_rmse \u003d evaluator_rmse.evaluate(lr_predictions)\nlr_r2 \u003d evaluator_r2.evaluate(lr_predictions)\n\n# Random Forest predictions\nrf_predictions \u003d rf_model.transform(test_data)\nrf_rmse \u003d evaluator_rmse.evaluate(rf_predictions)\nrf_r2 \u003d evaluator_r2.evaluate(rf_predictions)\n\n# GBT predictions\ngbt_predictions \u003d gbt_model.transform(test_data)\ngbt_rmse \u003d evaluator_rmse.evaluate(gbt_predictions)\ngbt_r2 \u003d evaluator_r2.evaluate(gbt_predictions)\ngbt_mae \u003d evaluator_mae.evaluate(gbt_predictions)\n\nprint(\"\u003d\u003d\u003d Linear Regression Evaluation \u003d\u003d\u003d\")\nprint(f\"RMSE: {lr_rmse:.4f}, R2: {lr_r2:.4f}\")\n\nprint(\"\\n\u003d\u003d\u003d Random Forest Evaluation \u003d\u003d\u003d\")\nprint(f\"RMSE: {rf_rmse:.4f}, R2: {rf_r2:.4f}\")\n\nprint(\"\\n\u003d\u003d\u003d Gradient Boosted Trees Evaluation \u003d\u003d\u003d\")\nprint(f\"RMSE: {gbt_rmse:.4f}\")\nprint(f\"R-2: {gbt_r2:.4f}\")\nprint(f\"MAE: {gbt_mae:.4f}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Find patterns where evapotranspiration \u003c 1.5mm\nlow_et \u003d df_features.filter(col(\"evapotranspiration\") \u003c 1.5)\n\nprint(\"\u003d\u003d\u003d Conditions for Evapotranspiration \u003c 1.5mm \u003d\u003d\u003d\")\nprint(f\"Number of days with ET \u003c 1.5mm: {low_et.count()}\")\n\nlow_et_stats \u003d low_et.agg(\n    avg(\"precipitation_hours\").alias(\"mean_precipitation_hours\"),\n    avg(\"sunshine_duration\").alias(\"mean_sunshine_duration\"),\n    avg(\"wind_speed\").alias(\"mean_wind_speed\"))\n\nprint(\"\\nMean values when evapotranspiration \u003c 1.5mm:\")\nlow_et_stats.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport random\nfrom pyspark.sql.types import StructType, StructField, DoubleType\n\nprint(\"PREDICTION: Best Achievable Weather Conditions (GBT + Random Search)\")\nprint(\"(Goal: Minimal Realistic ET for May using Non-Linear Model)\")\n\n# Random Grid Search Parameters\n# Compared to the mean values to have evapotranspiration \u003c 1.5mm: in the month of march \n# mean_precipitation_hours - 22.134328358208954\n# mean_sunshine_duration_seconds 1593.0579850746274\n# mean_wind_speed - 18.490298507462686\n\nNUM_SAMPLES \u003d 50000\nMIN_SUNSHINE \u003d 0.0         # 0.44 hours is very close to 0\nMAX_SUNSHINE \u003d 3600.0      # Cap at 1 hour (3600s) to force that low-sunshine similarity\nMIN_WIND \u003d 15.0            # Range around the 18.5 km/h mean\nMAX_WIND \u003d 25.0            # Allow it to go higher to see if more wind helps even more\nMIN_PRECIP \u003d 20.0          # Force high rain (centered on 22h)\nMAX_PRECIP \u003d 24.0          # Max possible\n\nprint(f\"Generating {NUM_SAMPLES} synthetic realistic weather points...\")\n\nsynthetic_data \u003d []\nfor _ in range(NUM_SAMPLES):\n    synthetic_data.append((\n        random.uniform(MIN_PRECIP, MAX_PRECIP),\n        random.uniform(MIN_SUNSHINE, MAX_SUNSHINE),\n        random.uniform(MIN_WIND, MAX_WIND)\n    ))\n\n# Create DataFrame\nschema \u003d StructType([\n    StructField(\"precipitation_hours\", DoubleType(), True),\n    StructField(\"sunshine_duration\", DoubleType(), True),\n    StructField(\"wind_speed\", DoubleType(), True)\n])\n\ndf_synthetic \u003d spark.createDataFrame(synthetic_data, schema)\n\n# Transform features\ndf_synthetic_assembled \u003d assembler.transform(df_synthetic)\ndf_synthetic_scaled \u003d scaler_model.transform(df_synthetic_assembled)\n\n# Predict using GBT\npredictions \u003d gbt_model.transform(df_synthetic_scaled)\n\n# Find minimum\nbest_result \u003d predictions.orderBy(\"prediction\").first()\nmin_et \u003d best_result[\"prediction\"]\n\nprint(f\"\\nOptimization Complete.\")\nprint(f\"Lowest Predicted ET found: {min_et:.4f} mm\")\n\nrecommended_stats \u003d {\n    \u0027precip\u0027: best_result[\"precipitation_hours\"],\n    \u0027sun\u0027: best_result[\"sunshine_duration\"],\n    \u0027wind\u0027: best_result[\"wind_speed\"]\n}\n\nprint(f\"\\n*** Recommended Values for May 2026 ***\")\nprint(f\"Precipitation Hours: {recommended_stats[\u0027precip\u0027]:.2f} hours\")\nprint(f\"Sunshine Duration: {recommended_stats[\u0027sun\u0027]:.2f} seconds ({recommended_stats[\u0027sun\u0027]/3600:.2f} hours)\")\nprint(f\"Wind Speed: {recommended_stats[\u0027wind\u0027]:.2f} km/h\")\n\nprint(f\"\\nModel Predicted Evapotranspiration (GBT): {min_et:.4f} mm\")\n\nif min_et \u003c 1.5:\n    print(\"SUCCESS: GBT found a realistic scenario \u003c 1.5mm!\")\nelse:\n    print(\"NOTE: Even with GBT, the lowest realistic ET is above 1.5mm.\")\n    print(\"      This represents the absolute best-case scenario found by the model.\")"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}